{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建虚拟环境\n",
    "`conda create -n langchain python=3.11`\n",
    "\n",
    "激活虚拟环境\n",
    "`conda activate langchain`\n",
    "\n",
    "安装langchain\n",
    "`pip install langchain==0.1.13`\n",
    "`pip install langchain-openai`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Model 和 Chat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain 调用大语言模型时需要密钥，这里建议直接以环境变量的方式加载 openai-key，\n",
    "```\n",
    "export OPENAI_API_KEY = \"密钥\"\n",
    "export OPENAI_API_BASE = \"调用api\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Model\n",
    "LLM 模型主要用于文本补全、文本嵌入、文本相似度查找等文本工作。\n",
    "\n",
    "LangChain调用 LLM Model 的步骤也很简单，初始化的时候指定模型名称，运行时输入字符串即可。\n",
    "\n",
    "在初始化模型对象时，LangChain会自动检测和加载环境变量。\n",
    "示例——使用 LangChain 调用 LLM Model 以完成文本补全："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好啊\\n\\n今天天气真好啊\\n\\n是的，今天的天气确实很好，阳光明媚，空气清新，适合出门散步或做其他户外活动。让我们好好享受这样的美好天气吧！'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# find_dotenv() 寻找并定位 .env 文件的路径\n",
    "# load_dotenv() 读取该 .env 文件，并将其中的环境变量加载到当前的运行环境中  \n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 读取本地/项目的环境变量\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct')\n",
    "llm.invoke(\"今天天气真\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Model 是通用模型，一般用于简单的单论文本交互。Chat Model 针对对话任务进行了优化，可以进行多轮对话，例如客服机器人和智能助手。\n",
    "\n",
    "Chat Model 引入了**角色**的概念，每条消息都有对应的角色：\n",
    "1. user：用户消息。消息内容为用户输入的问题，在 LangChain 中，以HumanMessage表示。\n",
    "\n",
    "2. assistant：助手消息。消息内容是模型做出的回答，可以通过助手消息提供模型的历史回答，达到记忆对话的效果。在 LangChain 中以AIMessage表示。\n",
    "\n",
    "3. system：系统消息。用于设定对话的背景或上下文，可以帮助模型理解它在对话中的角色和任务，提高模型在对话中的回答质量。在 LangChain 中以SystemMessage表示。比如，让模型扮演一个高级开发工程师，可以SystemMessage(content = \"你是一个专业的高级开发工程师\")，这样能帮忙模型在对话中做出更好的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Model 接受一个消息列表作为输入，消息列表可以包含 1 个SystemMessage，多个HumanMessage和AIMessage，当然，最后一个需要是HumanMessage，填入用户期望回答的问题。LangChain将会输出一个AIMessage，作为问题的答案。  \n",
    "<mark>这一机制使得我们可以用户与 AI assistant 的每轮对话都加入到消息列表，使得后续对话具有前后连贯性。</mark>  \n",
    "LangChain 调用 Chat Model 的示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1 + 1 equals 2.', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 20, 'total_tokens': 28}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-65bdcfff-db22-4e31-ae00-234afb92cee1-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# find_dotenv() 寻找并定位 .env 文件的路径\n",
    "# load_dotenv() 读取该 .env 文件，并将其中的环境变量加载到当前的运行环境中  \n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "input_messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(content=\"1+1=?\"),\n",
    "]\n",
    "chat.invoke(input_messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
